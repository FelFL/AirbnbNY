{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and merging all listings datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to edit each df and creating a list of them to concatenate\n",
    "listings_Bronx = []\n",
    "listings_Brooklyn = []\n",
    "listings_Manhattan = []\n",
    "listings_Queens = []\n",
    "listings_StatenIsland = []\n",
    "\n",
    "#Getting the common columns\n",
    "column_list = [\"id\",\"neighbourhood_group_cleansed\",\"neighbourhood_cleansed\",\"latitude\",\"longitude\",\n",
    "                   \"room_type\",\"property_type\",\"accommodates\",\"bedrooms\",\"beds\",\"price\",\"amenities\"]\n",
    "\n",
    "property_list = [\"Apartment\",\"House\",\"Townhouse\",\"Loft\",\"Condominium\"]\n",
    "\n",
    "def clean_listings(df,year):\n",
    "    \n",
    "    df = df[[x for x in df.columns if x in column_list]]\n",
    "    df[\"property_type\"] = df[\"property_type\"].str.replace(\"Entire \",\"\")\n",
    "    df[\"property_type\"] = df[\"property_type\"].str.replace(\"Private room in \",\"\")\n",
    "    df[\"property_type\"] = df[\"property_type\"].str.replace(\"Shared room in \",\"\")\n",
    "    df[\"property_type\"] = df[\"property_type\"].str.replace(\"Room in \",\"\")\n",
    "    df[\"property_type\"] = df[\"property_type\"].str.title()\n",
    "    df = df[df[\"property_type\"].isin(property_list)]\n",
    "    df[\"database_year\"] = year\n",
    "    \n",
    "    Bronx, Brooklyn, Manhattan, Queens, StatenIsland = [x for _, x in df.groupby(df[\"neighbourhood_group_cleansed\"])]\n",
    "    df_list = (Manhattan , Brooklyn , Queens , Bronx , StatenIsland)\n",
    "       \n",
    "    listings_Bronx.append(Bronx)\n",
    "    listings_Brooklyn.append(Brooklyn)\n",
    "    listings_Manhattan.append(Manhattan)\n",
    "    listings_Queens.append(Queens)\n",
    "    listings_StatenIsland.append(StatenIsland)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_amenities(df):\n",
    "    \n",
    "    df_clusterid = df[[\"id\",\"cluster\"]]\n",
    "    df_amenities = df[[\"amenities\"]]\n",
    "    \n",
    "    df_amenities[\"amenities\"] = df_amenities[\"amenities\"].str.replace(\"{\", \"[\").replace(\"}\",\"]\")\n",
    "    df_amenities = df_amenities[\"amenities\"].str.replace('\\[|\"|\\]',\"\").str.get_dummies(\",\")\n",
    "    df_amenities.columns = df_amenities.columns.str.replace(\" \",\"\").str.replace(\"}\",\"\")\n",
    "    df_amenities.columns = df_amenities.columns.str.split(\"\\\\\").str[0]\n",
    "    df_amenities = df_amenities.groupby(level=0, axis=1).sum()\n",
    "    \n",
    "    df_amenities[[\"id\",\"cluster\"]] = df_clusterid[[\"id\",\"cluster\"]]\n",
    "    df = df.drop([\"amenities\"], axis = 1)\n",
    "    \n",
    "\n",
    "    return  df_amenities, df\n",
    "\n",
    "#Open all listings datasets \n",
    "df20 = pd.read_csv(\"Raw_Datasets/listings2020.csv\")\n",
    "df19 = pd.read_csv(\"Raw_Datasets/listings2019.csv\")\n",
    "df18 = pd.read_csv(\"Raw_Datasets/listings2018.csv\")\n",
    "df17 = pd.read_csv(\"Raw_Datasets/listings2017.csv\")\n",
    "   \n",
    "#Cleaning all the listings\n",
    "clean_listings(df20,2020)\n",
    "clean_listings(df19,2019)\n",
    "clean_listings(df18,2018)\n",
    "clean_listings(df17,2017)\n",
    "\n",
    "#Creating df for each borough and one for all\n",
    "Bronx = pd.concat(listings_Bronx)\n",
    "Brooklyn = pd.concat(listings_Brooklyn)\n",
    "Manhattan = pd.concat(listings_Manhattan)\n",
    "Queens = pd.concat(listings_Queens)\n",
    "StatenIsland = pd.concat(listings_StatenIsland)\n",
    "\n",
    "#Creating a list to clustering each borough\n",
    "borough_list = [Bronx, Brooklyn, Manhattan, Queens, StatenIsland]\n",
    "\n",
    "for df in borough_list:\n",
    "    \n",
    "    #Getting the geopoints of each listing\n",
    "    geopoints = df[[\"latitude\",\"longitude\"]].to_numpy()    \n",
    "    \n",
    "    #Clustering by Kmeans\n",
    "    kmeans = KMeans(n_clusters=10)\n",
    "    kmeans.fit(geopoints)\n",
    "    clusters = kmeans.fit_predict(geopoints)\n",
    "    df[\"cluster\"] = clusters    \n",
    "\n",
    "#Getting the amenities dataset by borough \n",
    "Bronx_amenities, Bronx_listings = get_amenities(Bronx)\n",
    "Brooklyn_amenities, Brooklyn_listings = get_amenities(Brooklyn)\n",
    "Manhattan_amenities, Manhattan_listings = get_amenities(Manhattan)\n",
    "Queens_amenities, Queens_listings = get_amenities(Queens)\n",
    "StatenIsland_amenities, StatenIsland_listings = get_amenities(StatenIsland)\n",
    "    \n",
    "#Creating a listings with all boroughs\n",
    "Listings = pd.concat([Bronx_listings, Brooklyn_listings, Manhattan_listings, Queens_listings, StatenIsland_listings])\n",
    "\n",
    "#Creating a CSV for each borough listings df\n",
    "Listings.to_csv(\"All_listings.csv\", sep =\",\" , index = False)\n",
    "Bronx_listings.to_csv(\"Bronx_listings.csv\", sep =\",\" , index = False)\n",
    "Brooklyn_listings.to_csv(\"Brooklyn_listings.csv\", sep =\",\" , index = False)\n",
    "Manhattan_listings.to_csv(\"Manhattan_listings.csv\", sep =\",\" , index = False)\n",
    "Queens_listings.to_csv(\"Queens_listings.csv\", sep =\",\" , index = False)\n",
    "StatenIsland_listings.to_csv(\"StatenIsland_listings.csv\", sep =\",\" , index = False)\n",
    "\n",
    "#Creating a CSV for each borough amenities df\n",
    "Bronx_amenities.to_csv(\"Bronx_amenities.csv\", sep =\",\" , index = False)\n",
    "Brooklyn_amenities.to_csv(\"Brooklyn_amenities.csv\", sep =\",\" , index = False)\n",
    "Manhattan_amenities.to_csv(\"Manhattan_amenities.csv\", sep =\",\" , index = False)\n",
    "Queens_amenities.to_csv(\"Queens_amenities.csv\", sep =\",\" , index = False)\n",
    "StatenIsland_amenities.to_csv(\"StatenIsland_amenities.csv\", sep =\",\" , index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and merging all calendar datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_calendar(CSV):\n",
    "\n",
    "    df = pd.read_csv(CSV)\n",
    "    df = df.rename(columns={\"listing_id\" : \"id\"})\n",
    "    df = df[[\"id\",\"date\",\"price\"]]\n",
    "\n",
    "    df = df[df[\"price\"].notnull()]\n",
    "    df[\"price\"] = df[\"price\"].str.split(\".\").str[0]\n",
    "    df[\"price\"] = df[\"price\"].str.replace(\",\",\"\")\n",
    "    df[\"price\"] = df[\"price\"].str.replace(\"$\",\"\")\n",
    "    df[\"price\"] = df[\"price\"].astype(int)\n",
    "    \n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"year\"] = df[\"date\"].dt.year\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df = df.drop([\"date\"], axis = 1)\n",
    "    \n",
    "    df = df.groupby([\"id\",\"year\",\"month\"]).describe().iloc[:,1].reset_index()\n",
    "    df.columns = [\"id\",\"year\",\"month\",\"price\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "cal_Bronx = []\n",
    "cal_Brooklyn = []\n",
    "cal_Manhattan = []\n",
    "cal_Queens = []\n",
    "cal_StatenIsland = []\n",
    "\n",
    "Bronx_id = Bronx.id.to_list()\n",
    "Brooklyn_id = Brooklyn.id.to_list()\n",
    "Manhattan_id = Manhattan.id.to_list()\n",
    "Queens_id = Queens.id.to_list()\n",
    "StatenIsland_id = StatenIsland.id.to_list()\n",
    "\n",
    "def borough_calendar(df):\n",
    "    \n",
    "    df1 = df[df[\"id\"].isin(Bronx_id)]\n",
    "    df2 = df[df[\"id\"].isin(Brooklyn_id)]\n",
    "    df3 = df[df[\"id\"].isin(Manhattan_id)]\n",
    "    df4 = df[df[\"id\"].isin(Queens_id)]\n",
    "    df5 = df[df[\"id\"].isin(StatenIsland_id)]\n",
    "        \n",
    "    cal_Bronx.append(df1)\n",
    "    cal_Brooklyn.append(df2)\n",
    "    cal_Manhattan.append(df3)\n",
    "    cal_Queens.append(df4)\n",
    "    cal_StatenIsland.append(df5)\n",
    "    \n",
    "    return df1, df2, df3, df4, df5\n",
    "\n",
    "def concat_calendars(cal_list):\n",
    "    \n",
    "    df = pd.concat(cal_list)\n",
    "    df = df.groupby([\"id\",\"year\",\"month\"]).mean().reset_index()\n",
    "    df = df[df[\"year\"]>2017]\n",
    "    df[\"price\"] = df[\"price\"].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#Cleaning the calendar datasets\n",
    "calendar2021 = clean_calendar(\"Raw_Datasets/calendar2021.csv\")\n",
    "calendar2020 = clean_calendar(\"Raw_Datasets/calendar2020.csv\")\n",
    "calendar2019 = clean_calendar(\"Raw_Datasets/calendar2019.csv\")\n",
    "calendar2018 = clean_calendar(\"Raw_Datasets/calendar2018.csv\")\n",
    "calendar2017 = clean_calendar(\"Raw_Datasets/calendar2017.csv\")\n",
    "\n",
    "#Spliting by borough\n",
    "borough_calendar(calendar2021)\n",
    "borough_calendar(calendar2020)\n",
    "borough_calendar(calendar2019)\n",
    "borough_calendar(calendar2018)\n",
    "borough_calendar(calendar2017)\n",
    "\n",
    "#Concatenating by borough\n",
    "Bronx_calendar = concat_calendars(cal_Bronx)\n",
    "Brooklyn_calendar = concat_calendars(cal_Brooklyn)\n",
    "Manhattan_calendar = concat_calendars(cal_Manhattan)\n",
    "Queens_calendar = concat_calendars(cal_Queens)\n",
    "StatenIsland_calendar = concat_calendars(cal_StatenIsland)\n",
    "\n",
    "#Creating CSV file for each borough\n",
    "Bronx_calendar.to_csv(\"Bronx_calendar.csv\", sep =\",\" , index = False)\n",
    "Brooklyn_calendar.to_csv(\"Brooklyn_calendar.csv\", sep =\",\" , index = False)\n",
    "Manhattan_calendar.to_csv(\"Manhattan_calendar.csv\", sep =\",\" , index = False)\n",
    "Queens_calendar.to_csv(\"Queens_calendar.csv\", sep =\",\" , index = False)\n",
    "StatenIsland_calendar.to_csv(\"StatenIsland.csv\", sep =\",\" , index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
